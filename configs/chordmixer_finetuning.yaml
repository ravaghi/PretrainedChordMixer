defaults:
  - _self_
  - model: chordmixer_finetuning
  - loss: cross_entropy
  - dataset: ???
  - dataloader: chordmixer_finetuning
  - trainer: chordmixer
  - wandb: wandb

optimizer:
  _target_: torch.optim.Adam
  lr: 0.0005

general:
  name: ChordMixerFinetuning
  seed: 42
  device_id: 0
  batch_size: 2
  max_epochs: 30
  log_to_wandb: true
  use_multi_gpu: false
  save_dir: ${hydra:runtime.cwd}/logs/checkpoints/${general.name}

hydra:
  run:
    dir: ${hydra:runtime.cwd}/logs/hydra/outputs
