program: train.py
method: bayes
metric:
  goal: maximize
  name: test_accuracy

parameters:
  general.batch_size:
    max: 32
    min: 4
    q: 4
    distribution: q_uniform
  wandb.name:
    value: ""
  dataloader.mask_ratio:
    max: 0.50
    min: 0.05
    q: 0.05
    distribution: q_uniform
  dataloader.sequence_length:
    max: 10_000
    min: 1000
    q: 1000
    distribution: q_uniform
  optimizer.lr:
    max: 0.001
    min: 0.000001
    distribution: uniform
  model.decoder_track_size:
    values: [4, 8]
  model.encoder_prelinear_out_features:
    max: 1000
    min: 50
    q: 50
    distribution: q_uniform
  model.decoder_prelinear_out_features:
    max: 1000
    min: 50
    q: 50
    distribution: q_uniform

command:
  - ${env}
  - python
  - ${program}
  - --config-name=chordmixer_pretraining
  - general.max_epochs=10
  - ${args_no_hyphens}
